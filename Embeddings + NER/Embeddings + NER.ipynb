{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1741922488968,
     "user": {
      "displayName": "Esmeralda",
      "userId": "01211622725341252861"
     },
     "user_tz": 360
    },
    "id": "zqr8rEBO6ZkV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import unicodedata\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos para extraer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELOS = {\n",
    "    \"sentence-transformers\": 'Santp98/SBERT-pairs-bert-base-spanish-wwm-cased',\n",
    "    \"sentence_similarity\": 'hiiamsid/sentence_similarity_spanish_es'\n",
    "}\n",
    "\n",
    "CAMPOS = [\"Titulo\", \"resumen\", \"objetivos\", \"claves\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de NER's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo_ner(nombre_modelo=\"iEsmeralda/mrm8488-finetuned-ner-tech\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(nombre_modelo)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(nombre_modelo)\n",
    "    ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "    return ner_pipeline\n",
    "\n",
    "def agrupar_entidades_consecutivas(entidades):\n",
    "    if not entidades:\n",
    "        return []\n",
    "    entidades_agrupadas = []\n",
    "    entidad_actual = entidades[0].copy()\n",
    "    for i in range(1, len(entidades)):\n",
    "        entidad = entidades[i]\n",
    "        if entidad[\"entity_group\"] == entidad_actual[\"entity_group\"] and entidad[\"start\"] == entidad_actual[\"end\"] + 1:\n",
    "            entidad_actual[\"word\"] += \" \" + entidad[\"word\"]\n",
    "            entidad_actual[\"end\"] = entidad[\"end\"]\n",
    "            entidad_actual[\"score\"] = (entidad_actual[\"score\"] + entidad[\"score\"]) / 2\n",
    "        else:\n",
    "            entidades_agrupadas.append(entidad_actual)\n",
    "            entidad_actual = entidad.copy()\n",
    "    entidades_agrupadas.append(entidad_actual)\n",
    "    return entidades_agrupadas\n",
    "\n",
    "def extraer_ners(texto, ner_pipeline, max_tokens=512):\n",
    "    tokenizer = ner_pipeline.tokenizer\n",
    "    model = ner_pipeline.model\n",
    "\n",
    "    tokens = tokenizer.tokenize(texto)\n",
    "    entidades = []\n",
    "\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk_tokens = tokens[i:i+max_tokens]\n",
    "        chunk_text = tokenizer.convert_tokens_to_string(chunk_tokens)\n",
    "\n",
    "        # se asegura de que no se pase del limite del modelo de sentence_transformer y sentence_similarity (512 tokens)\n",
    "        if len(tokenizer(chunk_text)[\"input_ids\"]) > max_tokens:\n",
    "            continue\n",
    "\n",
    "        resultado_chunk = ner_pipeline(chunk_text)\n",
    "        entidades_chunk = agrupar_entidades_consecutivas(resultado_chunk)\n",
    "        entidades.extend(entidades_chunk)\n",
    "\n",
    "    return [entidad[\"word\"] for entidad in entidades]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo(nombre_modelo):\n",
    "    return SentenceTransformer(nombre_modelo)\n",
    "\n",
    "def obtener_embeddings(df, campo, modelo, ner_pipeline, max_tokens=512):\n",
    "    tokenizer = modelo.tokenizer if hasattr(modelo, 'tokenizer') else None\n",
    "    textos = df[campo].astype(str).tolist()\n",
    "    embeddings = []\n",
    "\n",
    "    for texto in textos:\n",
    "        ners = extraer_ners(texto, ner_pipeline)\n",
    "        texto_enriquecido = f\"{texto} {' '.join(ners)}\"\n",
    "\n",
    "        # tokeniza texto completo enriquecido\n",
    "        tokens = tokenizer.tokenize(texto_enriquecido) if tokenizer else texto_enriquecido.split()\n",
    "\n",
    "        if len(tokens) <= max_tokens:\n",
    "            vector = modelo.encode(texto_enriquecido)\n",
    "        else:\n",
    "            chunk_embeddings = []\n",
    "            for i in range(0, len(tokens), max_tokens):\n",
    "                chunk_text = \" \".join(tokens[i:i+max_tokens])\n",
    "                vec = modelo.encode(chunk_text)\n",
    "                chunk_embeddings.append(vec)\n",
    "            vector = sum(chunk_embeddings) / len(chunk_embeddings)\n",
    "\n",
    "        embeddings.append(vector)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def guardar_embeddings(embeddings, archivo_salida):\n",
    "    with open(archivo_salida, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocolos=pd.read_csv(\"protocolos_completo_limpios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocolos_acentuados=pd.read_csv(\"protocolos_completo_limpios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_texto(texto):\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "    return texto.lower()\n",
    "protocolos = protocolos.applymap(lambda x: normalizar_texto(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = protocolos\n",
    "    campo = input(\"Selecciona el campo (Titulo, resumen, objetivos, claves) para obtener sus PKL's: \").strip()\n",
    "\n",
    "    if campo not in df.columns:\n",
    "        print(\"El campo ingresado es invalido.\")\n",
    "        return\n",
    "\n",
    "    ruta_destino = os.path.join(\"pkl\")\n",
    "    os.makedirs(ruta_destino, exist_ok=True)\n",
    "\n",
    "    ner_pipeline = cargar_modelo_ner()\n",
    "\n",
    "    for clave_modelo, nombre_modelo in MODELOS.items():\n",
    "        print(f\"\\nProcesando modelo: {clave_modelo}\")\n",
    "        modelo = cargar_modelo(nombre_modelo)\n",
    "        embeddings_obtenidos = obtener_embeddings(df, campo, modelo, ner_pipeline)\n",
    "        archivo_embeddings = os.path.join(ruta_destino, f\"{campo}_{clave_modelo}_embeddings.pkl\")\n",
    "        guardar_embeddings(embeddings_obtenidos, archivo_embeddings)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consulta original: redes neuronales convulocionales\n",
      "Entidades NER detectadas: ['redes neuronales convulocionales']\n",
      "\n",
      "Top 5 resultados más similares:\n",
      "\n",
      "TT: 2016-B026\n",
      "- Titulo: Reconocimiento del Tránsito vehicular aplicando Redes Neuronales Profundas\n",
      "- Resumen: Tomando en cuenta el incremento del congestionamiento vial y el aumento de cámaras en  las calles en la Ciudad de México proponemos desarrollar una herramienta que realice el  reco...\n",
      "- Objetivos: Objetivos General Implementar una Red Neuronal Convolucional que haga uso del video tomado por cámaras  para reconocer y clasificar el congestionamiento vehicular. Particulares  Im...\n",
      "- Claves: Deep Learning, Redes Neuronales Profundas o Convolucionales, Visión por Computadora.\n",
      "Similitud total: 4.5067\n",
      "\n",
      "TT: 2016-A009\n",
      "- Titulo: Clasificador basado en redes neuronales profundas\n",
      "- Resumen: La solución de problemas de clasificación mediante aprendizaje profundo, es un área de creciente interés y aplicación constante en la  computación actual Una red neuronal artificia...\n",
      "- Objetivos: Diseñar, implementar y evaluar un algoritmo de aprendizaje profundo aplicado en la clasificación de imágenes digitales. Objetivos particulares Analizar y probar el algoritmos para ...\n",
      "- Claves: Redes Neuronales artificiales, reconocimiento de patrones, aprendizaje profundo, Retinopatia Diabética.\n",
      "Similitud total: 4.2962\n",
      "\n",
      "TT: 2023-A024\n",
      "- Titulo: Arquitectura de una red neuronal convolucional para el reconocimiento de\n",
      "expresiones faciales que representan emociones universales\n",
      "- Resumen: El presente Trabajo Terminal (TT) tiene como objetivo el desarrollo de una nueva arquitectura de red neuronal convolucional que permita el reconocimiento de expresiones faciales pa...\n",
      "- Objetivos: Desarrollar la arquitectura de una red neuronal convolucional entrenada para obtener una clasificación suave de emociones universales en expresiones faciales presentes en los rostr...\n",
      "- Claves: Reconocimiento de expresiones faciales, Redes neuronales convolucionales, Aprendizaje profundo, Emociones universales\n",
      "Similitud total: 4.2045\n",
      "\n",
      "TT: 2021-A012\n",
      "- Titulo: Detección de Tumor Cerebral con Redes Neuronales Artificiales\n",
      "- Resumen: Un problema frecuente en la ciencia médica es el tumor cerebral, esta anomalía es posible de identificar mediante una imagen por resonancia magnética, sin embargo, algunas veces su...\n",
      "- Objetivos: Desarrollar un prototipo de software orientado principalmente a médicos sin especialidad en la detección de tumores cerebrales, que le permita detectar neoplasias de diferentes tam...\n",
      "- Claves: Redes Neuronales Artificiales, Oncología, Inteligencia Artificial, Radiología, Neoplasia\n",
      "Similitud total: 4.1771\n",
      "\n",
      "TT: 2020-A042\n",
      "- Titulo: Prototipo de sistema de ayuda al diagnóstico de la esclerosis múltiple\n",
      "- Resumen: El uso de las imágenes de resonancia magnética (MRI) han sido de mucha ayuda a los médicos especialistas al momento de diagnosticar, tratar y dar seguimiento a las enfermedades o t...\n",
      "- Objetivos: El objetivo principal de este trabajo es diseñar e implementar un prototipo de sistema para la detección de lesiones causadas por la esclerosis múltiple, aplicando redes neuronales...\n",
      "- Claves: Redes neuronales, MRI, análisis de imágenes, esclerosis múltiple\n",
      "Similitud total: 4.1186\n",
      "\n",
      "Consulta original: procesamiento de lenguaje natural\n",
      "Entidades NER detectadas: ['procesamiento de lenguaje natural']\n",
      "\n",
      "Top 5 resultados más similares:\n",
      "\n",
      "TT: 2017-A039\n",
      "- Titulo: Transformación de palabras a vectores usando redes neuronales profundas para procesamiento de lenguaje natural\n",
      "- Resumen: En este trabajo terminal se desarrollará un módulo funcional capaz de hacer procesamiento de lenguaje natural para la recuperación de información, aplicando la técnica de convertir...\n",
      "- Objetivos: Diseñar, desarrollar e implementar un módulo para transformar palabras a vectores usando redes neuronales de aprendizaje profundo. Objetivos específicos Implementar un sistema de a...\n",
      "- Claves: Redes neuronales, Aprendizaje profundo, Procesamiento de Lenguaje Natural.\n",
      "Similitud total: 5.1812\n",
      "\n",
      "TT: 2018-B017\n",
      "- Titulo: Rank.me: modelo de lenguaje para la generación de preguntas y respuestas\n",
      "- Resumen: En el estudio de las ciencias de la computación y la inteligencia artificial, se han planteado diversos problemas a ser resueltos uno de ellos es el de la Comprensión por Máquina (...\n",
      "- Objetivos: El presente trabajo terminal tiene como objetivo diseñar un modelo que pueda ser utilizado para resolver las tareas de generación automática de preguntas y respuestas con un enfoqu...\n",
      "- Claves: Procesamiento del lenguaje natural, Machine learning, Inteligencia Artificial, Deep learn\n",
      "Similitud total: 4.5117\n",
      "\n",
      "TT: 2018-B124\n",
      "- Titulo: Sistema para la inferencia de redes regulatorias de genes a través del procesamiento de lenguaje natural\n",
      "- Resumen: El presente protocolo propone desarrollar un método computacional y una representación comprensible de inferencia de redes regulatorias de genes a través de tareas de procesamiento...\n",
      "- Objetivos: Objetivos Objetivo general 12 Desarrollar un método computacional replicable que sea capaz de ser utilizado para ayudar a inferir  redes regulatorias de genes a partir de archivos ...\n",
      "- Claves: Procesamiento de lenguaje natural, Ciencias de la computación, Redes regulatorias de genes.\n",
      "Similitud total: 4.4984\n",
      "\n",
      "TT: 2018-B046\n",
      "- Titulo: Traductor de lenguaje de señas mexicano a español(TRASEM)\n",
      "- Resumen: Desarrollar una herramienta para traducir un conjunto de frases de prueba del lenguaje de señas español, por medio del procesamiento de video y del procesamiento de lenguaje natura...\n",
      "- Objetivos: Objetivo General Desarrollar una herramienta de software para traducir un conjunto de señas de nivel básico del LSM al español, usando técnicas de procesamiento de video y lenguaje...\n",
      "- Claves: Ingeniería de Software, Programación, Procesamiento de Lenguaje Natural.\n",
      "Similitud total: 4.4764\n",
      "\n",
      "TT: 2020-A022\n",
      "- Titulo: Cifrado basada en procesamiento de lenguaje natural para evitar el perfiliamiento de usaurio \n",
      "- Resumen: El presente protocolo propone desarrollar un método de cifra do basado en procesamiento de lenguaje natural, con el cual se pretende evitar el perfilamiento de usuarios, específica...\n",
      "- Objetivos: Objetivos Objetivo general Desarrollar un método de cifrado basado en procesamiento de lenguaje natural para evitar el perfilamiento de usuarios, específicamente considerando los i...\n",
      "- Claves: Criptografía, Procesamiento de lenguaje natural, Perfilamiento de usuarios, Ciencias de la computación\n",
      "Similitud total: 4.3534\n"
     ]
    }
   ],
   "source": [
    "df = protocolos\n",
    "df_resultados_acentuados  = protocolos_acentuados\n",
    "ner_pipeline = cargar_modelo_ner()\n",
    "\n",
    "while True:\n",
    "    query = input(\"\\nIngresa el texto para comparar (o escribe 'salir' para terminar): \").strip()\n",
    "    if query.lower() == \"salir\":\n",
    "        break\n",
    "\n",
    "    print(f\"\\nConsulta original: {query}\")\n",
    "    entidades_query = extraer_ners(query, ner_pipeline)\n",
    "    print(\"Entidades NER detectadas:\", entidades_query)\n",
    "\n",
    "    query_enriquecida = f\"{query} {' '.join(entidades_query)}\" if entidades_query else query\n",
    "    query_con_contexto = f\"Este trabajo trata sobre {query_enriquecida}\"\n",
    "\n",
    "    df_resultados_acentuados = protocolos_acentuados.copy()\n",
    "    df_resultados_acentuados[\"sim_total\"] = 0\n",
    "\n",
    "    for clave_modelo, nombre_modelo in MODELOS.items():\n",
    "        modelo = SentenceTransformer(nombre_modelo)\n",
    "        embedding_query = modelo.encode(query_con_contexto, convert_to_tensor=False)\n",
    "\n",
    "        for campo in CAMPOS:\n",
    "            nombre_pkl = f\"{campo}_{clave_modelo}_embeddings.pkl\"\n",
    "            ruta_pkl = os.path.join(\"pkl\", nombre_pkl)\n",
    "\n",
    "            if not os.path.exists(ruta_pkl):\n",
    "                print(f\"Falta el archivo: {ruta_pkl}\")\n",
    "                continue\n",
    "\n",
    "            with open(ruta_pkl, \"rb\") as f:\n",
    "                embeddings_cargados = pickle.load(f)\n",
    "\n",
    "            simi_coseno = cosine_similarity([embedding_query], embeddings_cargados)[0]\n",
    "            df_resultados_acentuados[f\"{campo}_{clave_modelo}\"] = simi_coseno\n",
    "            df_resultados_acentuados[\"sim_total\"] += simi_coseno # ponderacion simple\n",
    "\n",
    "    df_resultados_acentuados = df_resultados_acentuados.sort_values(\"sim_total\", ascending=False).head(5)\n",
    "\n",
    "    print(\"\\nTop 5 resultados más similares:\")\n",
    "    for i, row in df_resultados_acentuados.iterrows():\n",
    "        print(f\"\\nTT: {row['TT']}\")\n",
    "        for campo in CAMPOS:\n",
    "            resumen = str(row[campo])\n",
    "            if len(resumen) > 180:\n",
    "                resumen = resumen[:180] + \"...\"\n",
    "            print(f\"- {campo.capitalize()}: {resumen}\")\n",
    "        print(f\"Similitud total: {row['sim_total']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPzXN+4UYNp1S1wOS6l9Smq",
   "mount_file_id": "1uZXBHOA-MUai9-JZwTDeGk_jhfiMVbG2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
