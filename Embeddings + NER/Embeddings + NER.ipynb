{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1741922488968,
     "user": {
      "displayName": "Esmeralda",
      "userId": "01211622725341252861"
     },
     "user_tz": 360
    },
    "id": "zqr8rEBO6ZkV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos para extraer embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELOS = {\n",
    "    \"sentence-transformers\": 'Santp98/SBERT-pairs-bert-base-spanish-wwm-cased',\n",
    "    \"sentence_similarity\": 'hiiamsid/sentence_similarity_spanish_es'\n",
    "}\n",
    "\n",
    "CAMPOS = [\"Titulo\", \"resumen\", \"objetivos\", \"claves\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción de NER's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo_ner(nombre_modelo=\"iEsmeralda/mrm8488-finetuned-ner-tech\"):\n",
    "    tokenizador = AutoTokenizer.from_pretrained(nombre_modelo) \n",
    "    modelo = AutoModelForTokenClassification.from_pretrained(nombre_modelo)\n",
    "    ner_pipeline = pipeline(\"ner\", model=modelo, tokenizer=tokenizador, aggregation_strategy=\"simple\")\n",
    "    # aggregation_strategy=\"simple\" indica que se deben agrupar los tokens que pertenezcan a una misma entidad, por ejemplo si el modelo detecta \"inteligencia\" y \"artificial\" \n",
    "    # como parte de una misma entidad, los junta en una sola: \"inteligencia artificial\"\n",
    "\n",
    "    return ner_pipeline\n",
    "\n",
    "# funcion para agrupar entidades consecutivas del mismo tipo, esto se hizo porque habia entidades que no fueron \"unidas\" a pesar del aggregation_strategy\n",
    "def agrupar_entidades_consecutivas(entidades):\n",
    "    # si no hay entidades, se regresa una lista vacia\n",
    "    if not entidades:\n",
    "        return []\n",
    "    entidades_agrupadas = [] \n",
    "    entidad_actual = entidades[0].copy() # se toma la primera entidad como \"base\" \n",
    "    for i in range(1, len(entidades)):\n",
    "        entidad = entidades[i]\n",
    "\n",
    "        # si la entidad es del mismo tipo y esta justo despues de la actual, entonces:\n",
    "        if entidad[\"entity_group\"] == entidad_actual[\"entity_group\"] and entidad[\"start\"] == entidad_actual[\"end\"] + 1:\n",
    "            # se une la palabra, se actualiza el fin y se promedia el puntaje de ambas entidades\n",
    "            entidad_actual[\"word\"] += \" \" + entidad[\"word\"]\n",
    "            entidad_actual[\"end\"] = entidad[\"end\"]\n",
    "            entidad_actual[\"score\"] = (entidad_actual[\"score\"] + entidad[\"score\"]) / 2\n",
    "        else:\n",
    "            # si no son consecutivas, se guarda la actual y se pasa a la siguiente entidad \n",
    "            entidades_agrupadas.append(entidad_actual)\n",
    "            entidad_actual = entidad.copy()\n",
    "    entidades_agrupadas.append(entidad_actual)\n",
    "    return entidades_agrupadas\n",
    "\n",
    "# funcion para extraer las entidades nombradas de un texto largo\n",
    "def extraer_ners(texto, ner_pipeline, max_tokens=512):\n",
    "    tokenizador = ner_pipeline.tokenizer\n",
    "    modelo = ner_pipeline.model\n",
    "\n",
    "    tokens = tokenizador.tokenize(texto)\n",
    "    entidades = []\n",
    "\n",
    "    # se recorre la lista completa de tokens en bloques de tamaño max_tokens ya que la mayoria de los modelos de transformers solo aceptan secuencias de hasta 512 tokens como maximo\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        bloque_de_tokens = tokens[i:i+max_tokens]\n",
    "\n",
    "        # la lista de tokens nombrada como bloque_de_tokens se pasa a texto plano porque el pipeline de ner espera un texto como entrada\n",
    "        bloque_texto = tokenizador.convert_tokens_to_string(bloque_de_tokens)\n",
    "\n",
    "        # se vuelve a tokenizar el texto del bloque para asegurarse que no se pase del limite real de tokens del modelo\n",
    "        if len(tokenizador(bloque_texto)[\"input_ids\"]) > max_tokens:\n",
    "            # si el bloque excede el limite de 512 tokens, se salta \n",
    "            continue\n",
    "\n",
    "        # se aplica el pipeline de ner al bloque de texto para obtener las entidades detectadas en ese bloque\n",
    "        entidades_en_bloque = ner_pipeline(bloque_texto)\n",
    "        entidades_agrupadas_bloque = agrupar_entidades_consecutivas(entidades_en_bloque)\n",
    "        entidades.extend(entidades_agrupadas_bloque)\n",
    "\n",
    "    return [entidad[\"word\"] for entidad in entidades]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_modelo(nombre_modelo):\n",
    "    return SentenceTransformer(nombre_modelo)\n",
    "\n",
    "# funcion para obtener los vectores de embeddings a partir de los textos y las entidades reconocidas\n",
    "def obtener_embeddings(df, campo, modelo, ner_pipeline, max_tokens=512):\n",
    "    tokenizador = modelo.tokenizer if hasattr(modelo, 'tokenizer') else None\n",
    "    textos = df[campo].astype(str).tolist()\n",
    "    embeddings = []\n",
    "\n",
    "    for texto in textos:\n",
    "        entidades = extraer_ners(texto, ner_pipeline)\n",
    "        texto_enriquecido = f\"{texto} {' '.join(entidades)}\" # se crea un nuevo texto que combina el original con las entidades encontradas\n",
    "\n",
    "        # se tokeniza el texto enriquecido con el tokenizador del modelo o se separa por espacios si no hay un tokenizador\n",
    "        tokens = tokenizador.tokenize(texto_enriquecido) if tokenizador else texto_enriquecido.split()\n",
    "\n",
    "        if len(tokens) <= max_tokens:\n",
    "            embedding = modelo.encode(texto_enriquecido)\n",
    "        else:\n",
    "            embeddings_por_bloque = [] # si se excede el limite de tokens, se divide el texto en bloques\n",
    "            \n",
    "            for i in range(0, len(tokens), max_tokens):\n",
    "                bloque_texto = \" \".join(tokens[i:i+max_tokens])\n",
    "                embedding_bloque = modelo.encode(bloque_texto)\n",
    "                embeddings_por_bloque.append(embedding_bloque)\n",
    "            embedding = sum(embeddings_por_bloque) / len(embeddings_por_bloque)\n",
    "\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# funcion para guardar los embeddings generados en un archivo con formato binario\n",
    "def guardar_embeddings(embeddings, archivo_salida):\n",
    "    with open(archivo_salida, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocolos=pd.read_csv(\"protocolos_completo_limpios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocolos_acentuados=pd.read_csv(\"protocolos_completo_limpios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_texto(texto):\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
    "    return texto.lower()\n",
    "protocolos = protocolos.applymap(lambda x: normalizar_texto(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = protocolos\n",
    "    campo = input(\"Selecciona el campo (Titulo, resumen, objetivos, claves) para obtener sus PKL's: \").strip()\n",
    "\n",
    "    if campo not in df.columns:\n",
    "        print(\"El campo ingresado es invalido.\")\n",
    "        return\n",
    "\n",
    "    ruta_destino = os.path.join(\"pkl\")\n",
    "    os.makedirs(ruta_destino, exist_ok=True)\n",
    "\n",
    "    ner_pipeline = cargar_modelo_ner()\n",
    "\n",
    "    for clave_modelo, nombre_modelo in MODELOS.items():\n",
    "        print(f\"\\nProcesando modelo: {clave_modelo}\")\n",
    "        modelo = cargar_modelo(nombre_modelo)\n",
    "        embeddings_obtenidos = obtener_embeddings(df, campo, modelo, ner_pipeline)\n",
    "        archivo_embeddings = os.path.join(ruta_destino, f\"{campo}_{clave_modelo}_embeddings.pkl\")\n",
    "        guardar_embeddings(embeddings_obtenidos, archivo_embeddings)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consulta original: redes neuronales convolucionales\n",
      "Entidades NER detectadas: ['redes neuronales convolucionales']\n",
      "\n",
      "Top 5 resultados más similares:\n",
      "\n",
      "TT: 2016-B026\n",
      "- Titulo: Reconocimiento del Tránsito vehicular aplicando Redes Neuronales Profundas\n",
      "- Resumen: Tomando en cuenta el incremento del congestionamiento vial y el aumento de cámaras en  las calles en la Ciudad de México proponemos desarrollar una herramienta que realice el  reco...\n",
      "- Objetivos: Objetivos General Implementar una Red Neuronal Convolucional que haga uso del video tomado por cámaras  para reconocer y clasificar el congestionamiento vehicular. Particulares  Im...\n",
      "- Claves: Deep Learning, Redes Neuronales Profundas o Convolucionales, Visión por Computadora.\n",
      "Similitud total: 4.6636\n",
      "\n",
      "TT: 2016-B029\n",
      "- Titulo: Sistema de Clasificación de Razas Caninas Mediante Redes Neuronales Convolucionales\n",
      "- Resumen: En el presente protocolo se describe una propuesta para desarrollar un sistema computacional con arquitectura cliente- servidor capaz de clasificar visualmente los canes más comune...\n",
      "- Objetivos: Desarrollar un sistema computacional que clasifique automáticamente a las razas caninas más comunes en la Ciudad de México con base en las razas establecidas por la Federación Cino...\n",
      "- Claves: Redes neuronales convolucionales, Redes de computadoras, Análisis de imágenes, Inteligencia artificial.\n",
      "Similitud total: 4.6566\n",
      "\n",
      "TT: 2016-A009\n",
      "- Titulo: Clasificador basado en redes neuronales profundas\n",
      "- Resumen: La solución de problemas de clasificación mediante aprendizaje profundo, es un área de creciente interés y aplicación constante en la  computación actual Una red neuronal artificia...\n",
      "- Objetivos: Diseñar, implementar y evaluar un algoritmo de aprendizaje profundo aplicado en la clasificación de imágenes digitales. Objetivos particulares Analizar y probar el algoritmos para ...\n",
      "- Claves: Redes Neuronales artificiales, reconocimiento de patrones, aprendizaje profundo, Retinopatia Diabética.\n",
      "Similitud total: 4.6043\n",
      "\n",
      "TT: 2023-A024\n",
      "- Titulo: Arquitectura de una red neuronal convolucional para el reconocimiento de\n",
      "expresiones faciales que representan emociones universales\n",
      "- Resumen: El presente Trabajo Terminal (TT) tiene como objetivo el desarrollo de una nueva arquitectura de red neuronal convolucional que permita el reconocimiento de expresiones faciales pa...\n",
      "- Objetivos: Desarrollar la arquitectura de una red neuronal convolucional entrenada para obtener una clasificación suave de emociones universales en expresiones faciales presentes en los rostr...\n",
      "- Claves: Reconocimiento de expresiones faciales, Redes neuronales convolucionales, Aprendizaje profundo, Emociones universales\n",
      "Similitud total: 4.5984\n",
      "\n",
      "TT: 2018-B124\n",
      "- Titulo: Sistema para la inferencia de redes regulatorias de genes a través del procesamiento de lenguaje natural\n",
      "- Resumen: El presente protocolo propone desarrollar un método computacional y una representación comprensible de inferencia de redes regulatorias de genes a través de tareas de procesamiento...\n",
      "- Objetivos: Objetivos Objetivo general 12 Desarrollar un método computacional replicable que sea capaz de ser utilizado para ayudar a inferir  redes regulatorias de genes a partir de archivos ...\n",
      "- Claves: Procesamiento de lenguaje natural, Ciencias de la computación, Redes regulatorias de genes.\n",
      "Similitud total: 4.4321\n",
      "\n",
      "Consulta original: procesamiento de lenguaje natural\n",
      "Entidades NER detectadas: ['procesamiento de lenguaje natural']\n",
      "\n",
      "Top 5 resultados más similares:\n",
      "\n",
      "TT: 2017-A039\n",
      "- Titulo: Transformación de palabras a vectores usando redes neuronales profundas para procesamiento de lenguaje natural\n",
      "- Resumen: En este trabajo terminal se desarrollará un módulo funcional capaz de hacer procesamiento de lenguaje natural para la recuperación de información, aplicando la técnica de convertir...\n",
      "- Objetivos: Diseñar, desarrollar e implementar un módulo para transformar palabras a vectores usando redes neuronales de aprendizaje profundo. Objetivos específicos Implementar un sistema de a...\n",
      "- Claves: Redes neuronales, Aprendizaje profundo, Procesamiento de Lenguaje Natural.\n",
      "Similitud total: 5.1812\n",
      "\n",
      "TT: 2018-B017\n",
      "- Titulo: Rank.me: modelo de lenguaje para la generación de preguntas y respuestas\n",
      "- Resumen: En el estudio de las ciencias de la computación y la inteligencia artificial, se han planteado diversos problemas a ser resueltos uno de ellos es el de la Comprensión por Máquina (...\n",
      "- Objetivos: El presente trabajo terminal tiene como objetivo diseñar un modelo que pueda ser utilizado para resolver las tareas de generación automática de preguntas y respuestas con un enfoqu...\n",
      "- Claves: Procesamiento del lenguaje natural, Machine learning, Inteligencia Artificial, Deep learn\n",
      "Similitud total: 4.5117\n",
      "\n",
      "TT: 2018-B124\n",
      "- Titulo: Sistema para la inferencia de redes regulatorias de genes a través del procesamiento de lenguaje natural\n",
      "- Resumen: El presente protocolo propone desarrollar un método computacional y una representación comprensible de inferencia de redes regulatorias de genes a través de tareas de procesamiento...\n",
      "- Objetivos: Objetivos Objetivo general 12 Desarrollar un método computacional replicable que sea capaz de ser utilizado para ayudar a inferir  redes regulatorias de genes a partir de archivos ...\n",
      "- Claves: Procesamiento de lenguaje natural, Ciencias de la computación, Redes regulatorias de genes.\n",
      "Similitud total: 4.4984\n",
      "\n",
      "TT: 2018-B046\n",
      "- Titulo: Traductor de lenguaje de señas mexicano a español(TRASEM)\n",
      "- Resumen: Desarrollar una herramienta para traducir un conjunto de frases de prueba del lenguaje de señas español, por medio del procesamiento de video y del procesamiento de lenguaje natura...\n",
      "- Objetivos: Objetivo General Desarrollar una herramienta de software para traducir un conjunto de señas de nivel básico del LSM al español, usando técnicas de procesamiento de video y lenguaje...\n",
      "- Claves: Ingeniería de Software, Programación, Procesamiento de Lenguaje Natural.\n",
      "Similitud total: 4.4764\n",
      "\n",
      "TT: 2020-A022\n",
      "- Titulo: Cifrado basada en procesamiento de lenguaje natural para evitar el perfiliamiento de usaurio \n",
      "- Resumen: El presente protocolo propone desarrollar un método de cifra do basado en procesamiento de lenguaje natural, con el cual se pretende evitar el perfilamiento de usuarios, específica...\n",
      "- Objetivos: Objetivos Objetivo general Desarrollar un método de cifrado basado en procesamiento de lenguaje natural para evitar el perfilamiento de usuarios, específicamente considerando los i...\n",
      "- Claves: Criptografía, Procesamiento de lenguaje natural, Perfilamiento de usuarios, Ciencias de la computación\n",
      "Similitud total: 4.3534\n",
      "\n",
      "Consulta original: machine learning\n",
      "Entidades NER detectadas: ['mach', '##ine learning']\n",
      "\n",
      "Top 5 resultados más similares:\n",
      "\n",
      "TT: 2020-B058\n",
      "- Titulo: Aplicación web para reforzamiento de matecamáticas para nivel secundaria mediante quizzes con  análisis de datos aplicando métodos de machine learning\n",
      "- Resumen: El siguiente Protocolo de Trabajo Terminal presenta un sistema de clasificación el cual permita reforzar los aprendizajes adquiridos de matemáticas en la educación secundaria, medi...\n",
      "- Objetivos: Crear una aplicación Web para reforzar conocimientos de álgebra de los estudiantes de nivel secundaria mediante quizzes y realizando retroalimentación personalizadas mediante el an...\n",
      "- Claves: Aplicación web, machine learning, neural networks, Sistema de recomendaciones basado en contenido\n",
      "Similitud total: 4.7231\n",
      "\n",
      "TT: 2020-A059\n",
      "- Titulo: Teaching Aid. Aplicación web para la creación de instrumentos de evaluación en el idioma inglés\n",
      "- Resumen: Se propone realizar una aplicación web que entre diferentes funciones, se enfoque en la creación de instrumentos de evaluación de manera fácil para posteriormente aplicarlos, conte...\n",
      "- Objetivos: Desarrollar una aplicación web para docentes de nivel básico dedicados a la enseñanza del idioma inglés en los planteles de Celex de la Vocacional 8 del IPN, el cual les permita cr...\n",
      "- Claves: Examen, instrumentos de evaluación, Machine learning, aplicación web, patrones complejos.\n",
      "Similitud total: 4.7029\n",
      "\n",
      "TT: 2019-A032\n",
      "- Titulo: Machine learning aplicado al QSAR de los fármacos\n",
      "- Resumen: Desarrollar un sistema basado en los modelos de QSAR (Quantitative structure-activity relationship) y los métodos de Machine Learning que permitirá simular el procedimiento de un e...\n",
      "- Objetivos: Pro eso el objetivo principal es desarrollar un sistema basado en los modelos de QSAR (Quantitative Structure-Activity Relationship) y los métodos de Machine Learning usando el alg...\n",
      "- Claves: Bioinformática, Machine Learning, Modelado, Simulación.\n",
      "Similitud total: 4.4885\n",
      "\n",
      "TT: 2016-B082\n",
      "- Titulo: Sistema de Aprendizaje Adaptativo para las Matemáticas del Examen de Ingreso al IPN\n",
      "- Resumen: Actualmente en México 9 de cada 10 aspirantes de Educación Superior (UNAM, UAM, IPN) son rechazados [1] En el IPN el examen referente al área de Ciencias Físico Matemáticas contien...\n",
      "- Objetivos: Desarrollar una plataforma web de aprendizaje adaptativo para el área de matemáticas de conocimiento general, atendiendo ramas como álgebra, geometría y trigonometría, además de ra...\n",
      "- Claves: aprendizaje adaptativo, aprendizaje Máquina, Departamento de Formación Básica, Redes Neuronales\n",
      "Similitud total: 4.4445\n",
      "\n",
      "TT: 2018-B017\n",
      "- Titulo: Rank.me: modelo de lenguaje para la generación de preguntas y respuestas\n",
      "- Resumen: En el estudio de las ciencias de la computación y la inteligencia artificial, se han planteado diversos problemas a ser resueltos uno de ellos es el de la Comprensión por Máquina (...\n",
      "- Objetivos: El presente trabajo terminal tiene como objetivo diseñar un modelo que pueda ser utilizado para resolver las tareas de generación automática de preguntas y respuestas con un enfoqu...\n",
      "- Claves: Procesamiento del lenguaje natural, Machine learning, Inteligencia Artificial, Deep learn\n",
      "Similitud total: 4.3578\n"
     ]
    }
   ],
   "source": [
    "df = protocolos\n",
    "df_resultados_acentuados  = protocolos_acentuados\n",
    "ner_pipeline = cargar_modelo_ner()\n",
    "\n",
    "while True:\n",
    "    query = input(\"\\nIngresa el texto para comparar (o escribe 'salir' para terminar): \").strip()\n",
    "    if query.lower() == \"salir\":\n",
    "        break\n",
    "\n",
    "   \n",
    "    print(f\"\\nConsulta original: {query}\")\n",
    "    entidades_query = extraer_ners(query, ner_pipeline)\n",
    "    print(\"Entidades NER detectadas:\", entidades_query)\n",
    "\n",
    "    # si hay entidades, se enriquece un texto \n",
    "    query_enriquecida = f\"{query} {' '.join(entidades_query)}\" if entidades_query else query\n",
    "    query_con_contexto = f\"Este trabajo trata sobre {query_enriquecida}\" # se agrega contexto para el modelo, pues si solo ponemos la entidad, el modelo no sabe de que se trata\n",
    "\n",
    "    df_resultados_acentuados = protocolos_acentuados.copy()\n",
    "    df_resultados_acentuados[\"sim_total\"] = 0\n",
    "\n",
    "\n",
    "    for clave_modelo, nombre_modelo in MODELOS.items():\n",
    "        modelo = SentenceTransformer(nombre_modelo)\n",
    "        # se genera el embedding de la consulta con contexto\n",
    "        embedding_query = modelo.encode(query_con_contexto, convert_to_tensor=False)\n",
    "\n",
    "        for campo in CAMPOS:\n",
    "            # se construye el nombre del archivo .pkl que contiene los embeddings del campo\n",
    "            nombre_pkl = f\"{campo}_{clave_modelo}_embeddings.pkl\"\n",
    "            ruta_pkl = os.path.join(\"pkl\", nombre_pkl)\n",
    "            if not os.path.exists(ruta_pkl):\n",
    "                print(f\"Falta el archivo: {ruta_pkl}\")\n",
    "                continue\n",
    "\n",
    "            with open(ruta_pkl, \"rb\") as f:\n",
    "                embeddings_cargados = pickle.load(f)\n",
    "\n",
    "            # se calcula la similitud coseno entre el embedding de la consulta y los del archivo\n",
    "            simi_coseno = cosine_similarity([embedding_query], embeddings_cargados)[0]\n",
    "            df_resultados_acentuados[f\"{campo}_{clave_modelo}\"] = simi_coseno\n",
    "            # se acumula la similitud en la columna \"sim_total\" (ponderacion simple)\n",
    "            df_resultados_acentuados[\"sim_total\"] += simi_coseno\n",
    "\n",
    "    df_resultados_acentuados = df_resultados_acentuados.sort_values(\"sim_total\", ascending=False).head(5)\n",
    "    print(\"\\nTop 5 resultados más similares:\")\n",
    "    for i, row in df_resultados_acentuados.iterrows():\n",
    "        print(f\"\\nTT: {row['TT']}\")\n",
    "        for campo in CAMPOS:\n",
    "            resumen = str(row[campo])\n",
    "            if len(resumen) > 180:\n",
    "                resumen = resumen[:180] + \"...\"\n",
    "            print(f\"- {campo.capitalize()}: {resumen}\")\n",
    "        print(f\"Similitud total: {row['sim_total']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPzXN+4UYNp1S1wOS6l9Smq",
   "mount_file_id": "1uZXBHOA-MUai9-JZwTDeGk_jhfiMVbG2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
